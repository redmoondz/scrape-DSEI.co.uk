#!/usr/bin/env python3
"""
–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ DSEI Company Scraper
"""

import asyncio
import click
from pathlib import Path
import sys

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ src –≤ Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "src"))

from dsei_scraper import AsyncDSEICompanyScraper, Config


@click.command()
@click.option('--start-page', default=1, help='–ù–∞—á–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã')
@click.option('--max-pages', default=None, type=int, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
@click.option('--config', default=None, help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏')
@click.option('--output', default=None, help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É')
@click.option('--max-tasks', default=15, help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á')
@click.option('--verbose', '-v', is_flag=True, help='–ü–æ–¥—Ä–æ–±–Ω—ã–π –≤—ã–≤–æ–¥')
def async_scrape(start_page, max_pages, config, output, max_tasks, verbose):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —Å–∫—Ä–∞–ø–µ—Ä –∫–æ–º–ø–∞–Ω–∏–π DSEI —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –¥–æ 15 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á."""
    
    async def run_scraper():
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        if config:
            cfg = Config(config)
        else:
            cfg = Config()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ —Å–∫—Ä–∞–ø–µ—Ä–∞
        scraper = AsyncDSEICompanyScraper(cfg, max_concurrent_tasks=max_tasks)
        
        # –ó–∞–ø—É—Å–∫ —Å–∫—Ä–∞–ø–µ—Ä–∞
        try:
            await scraper.scrape_all_companies(
                start_page=start_page,
                max_pages=max_pages
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –≤—ã—Ö–æ–¥–Ω—ã–º —Ñ–∞–π–ª–æ–º –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if output:
                await scraper.save_to_csv(output)
            
            click.echo(f"üéâ –°–∫—Ä–∞–ø–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ! –°–æ–±—Ä–∞–Ω–æ {len(scraper.companies_data)} –∫–æ–º–ø–∞–Ω–∏–π.")
            
        except KeyboardInterrupt:
            click.echo("‚èπÔ∏è –°–∫—Ä–∞–ø–∏–Ω–≥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as e:
            click.echo(f"üí• –û—à–∏–±–∫–∞: {e}")
            raise
    
    # –ó–∞–ø—É—Å–∫ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏
    asyncio.run(run_scraper())


if __name__ == '__main__':
    async_scrape()
